{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-07-30T13:35:26.978955Z",
     "start_time": "2024-07-30T13:35:26.956743Z"
    }
   },
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch import nn\n",
    "from typing import Tuple\n",
    "import lightning as L\n",
    "from uncertainy.radio import get_radio_data_loaders\n",
    "from shared.data_module import DataModule\n",
    "from uncertainy.toy_regression import get_toy_regression_data_loaders\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T13:35:26.994071Z",
     "start_time": "2024-07-30T13:35:26.978955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "h = {  # hyperparameters\n",
    "    'ensemble_size': 3,\n",
    "    'dataset': 'TOY_REGRESSION',  #'TOY_REGRESSION', 'RADIO',\n",
    "    'dataset_path': '../data/',\n",
    "\n",
    "    'in_channels': 2,\n",
    "    'hidden_channels': 32,\n",
    "    'epochs': 2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'checkpoint_path': './saved_models',\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 4,\n",
    "\n",
    "    'limit_train_batches': 1.0,\n",
    "    'limit_val_batches': 1.0,\n",
    "    'limit_test_batches': 1.0,\n",
    "\n",
    "    'use_wandb': False,\n",
    "    'wandb_project': 'uncertainty',\n",
    "    'wandb_entity': 'oBoii',\n",
    "    'wandb_name': 'radio',\n",
    "\n",
    "    'train': True,  # Set this to false if you only want to evaluate the model\n",
    "    'fast_dev_run': True,\n",
    "    'overfit_batches': 0.0\n",
    "}"
   ],
   "id": "2872261e06ec0e70",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T13:35:27.010987Z",
     "start_time": "2024-07-30T13:35:26.995176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the script is being run in a Jupyter notebook\n",
    "if 'ipykernel' not in sys.modules:\n",
    "    # Parse command-line arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    for key, value in h.items():\n",
    "        if isinstance(value, bool):\n",
    "            parser.add_argument(f'--{key}', type=bool, default=value)\n",
    "        elif isinstance(value, int):\n",
    "            parser.add_argument(f'--{key}', type=int, default=value)\n",
    "        elif isinstance(value, float):\n",
    "            parser.add_argument(f'--{key}', type=float, default=value)\n",
    "        else:  # for str and potentially other types\n",
    "            parser.add_argument(f'--{key}', type=type(value), default=value)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Overwrite the default hyperparameters with the command-line arguments\n",
    "    h.update(vars(args))\n",
    "\n",
    "# In terminal, run:\n",
    "# python main.py --model SinkhornConvNetV2 --epochs 30"
   ],
   "id": "782efec0071d7437",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "class SimpleNet(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        hidden_size = 64\n",
    "\n",
    "        self.fc1 = nn.Linear(1, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.mu = nn.Linear(hidden_size, 1)\n",
    "        self.var = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        # negative log likelihood\n",
    "        self.NLL = torch.nn.GaussianNLLLoss(eps=1e-02)\n",
    "\n",
    "    def forward(self, x) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        h = torch.relu(self.fc2(h))\n",
    "        mu = self.mu(h)\n",
    "        var = torch.exp(self.var(h))\n",
    "        return mu, var\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        mu, var = self.forward(x)\n",
    "        loss = self.NLL(mu, y, var)  # strange order of arguments but it is what it is\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        mu, var = self.forward(x)\n",
    "        loss = self.NLL(mu, y, var)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        mu, var = self.forward(x)\n",
    "        loss = self.NLL(mu, y, var)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def save(self) -> None:\n",
    "        os.makedirs(h['checkpoint_path'], exist_ok=True)\n",
    "        torch.save(self.state_dict(), os.path.join(h['checkpoint_path'], 'model.pth'))\n",
    "\n",
    "    def load(self) -> 'SimpleNet':\n",
    "        self.load_state_dict(torch.load(os.path.join(h['checkpoint_path'], 'model.pth')))\n",
    "        self.eval()\n",
    "        return self\n",
    "\n",
    "\n",
    "class EnsembleNet(L.LightningModule):\n",
    "    def __init__(self, num_models: int):\n",
    "        super(EnsembleNet, self).__init__()\n",
    "        self.models = nn.ModuleList([SimpleNet() for _ in range(num_models)])\n",
    "        self.num_models = num_models\n",
    "\n",
    "    def forward(self, x) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        mus, vars = [], []\n",
    "        for model in self.models:\n",
    "            mu, var = model(x)\n",
    "            mus.append(mu)\n",
    "            vars.append(var)\n",
    "        mus = torch.stack(mus, dim=0)\n",
    "        vars = torch.stack(vars, dim=0)\n",
    "        return mus.mean(dim=0), vars.mean(dim=0)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        losses = []\n",
    "        for model in self.models:\n",
    "            mu, var = model(x)\n",
    "            loss = model.NLL(mu, y, var)\n",
    "            losses.append(loss)\n",
    "        return torch.stack(losses).mean()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        losses = []\n",
    "        for model in self.models:\n",
    "            mu, var = model(x)\n",
    "            loss = model.NLL(mu, y, var)\n",
    "            losses.append(loss)\n",
    "        return torch.stack(losses).mean()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        losses = []\n",
    "        for model in self.models:\n",
    "            mu, var = model(x)\n",
    "            loss = model.NLL(mu, y, var)\n",
    "            losses.append(loss)\n",
    "        return torch.stack(losses).mean()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers = [torch.optim.Adam(model.parameters(), lr=1e-3) for model in self.models]\n",
    "        return optimizers\n",
    "\n",
    "    def save(self) -> None:\n",
    "        os.makedirs(h['checkpoint_path'], exist_ok=True)\n",
    "        for i, model in enumerate(self.models):\n",
    "            torch.save(model.state_dict(), os.path.join(h['checkpoint_path'], f'model_{i}.pth'))\n",
    "\n",
    "    def load(self) -> 'EnsembleNet':\n",
    "        for i, model in enumerate(self.models):\n",
    "            model.load_state_dict(torch.load(os.path.join(h['checkpoint_path'], f'model_{i}.pth')))\n",
    "            model.eval()\n",
    "        return self\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T13:35:27.149878Z",
     "start_time": "2024-07-30T13:35:27.012576Z"
    }
   },
   "id": "b515de4dbeeb21c9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "39e7deae86e70d1d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T13:35:28.930367Z",
     "start_time": "2024-07-30T13:35:27.149878Z"
    }
   },
   "source": [
    "if h['dataset'] == 'RADIO':\n",
    "    train_loader, val_loader, test_loader = get_radio_data_loaders(\n",
    "        all_datasets_path=h['dataset_path'],\n",
    "        batch_size=h['batch_size'],\n",
    "        num_workers=h['num_workers'])\n",
    "elif h['dataset'] == 'TOY_REGRESSION':\n",
    "    train_loader, val_loader, test_loader = get_toy_regression_data_loaders(\n",
    "        batch_size=h['batch_size'],\n",
    "        num_workers=h['num_workers'],\n",
    "        num_points=500)\n",
    "\n",
    "    x, y = next(iter(test_loader))\n",
    "    plt.scatter(x, y)\n",
    "    # x ticks\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.show()\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset: {h['dataset']}\")\n",
    "\n",
    "datamodule = DataModule(train_loader, val_loader, test_loader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader shape: 350\n",
      "Val loader shape: 75\n",
      "Test loader shape: 75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "72ca7ac9073ef3ea",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T13:35:28.945931Z",
     "start_time": "2024-07-30T13:35:28.930367Z"
    }
   },
   "source": [
    "class CustomCallbacks(L.Callback):\n",
    "    pass\n",
    "\n",
    "#     def __init__(self, plot_every_n_epoch, num_pieces, wandb_logger: WandbLogger):\n",
    "#         super().__init__()\n",
    "#         self.plot_every_n_epoch = plot_every_n_epoch\n",
    "#         self.num_pieces = num_pieces\n",
    "#         self.wandb_logger = wandb_logger\n",
    "# \n",
    "#     def assemble_image(self, pieces):\n",
    "#         # pieces: [num_pieces, channels, height // num_pieces, width // num_pieces]\n",
    "#         num_pieces, channels, piece_height, piece_width = pieces.shape\n",
    "#         num_pieces_side = int(num_pieces ** 0.5)\n",
    "# \n",
    "#         # Reshape to [num_pieces_side, num_pieces_side, channels, piece_height, piece_width]\n",
    "#         pieces = pieces.view(num_pieces_side, num_pieces_side, channels, piece_height, piece_width)\n",
    "# \n",
    "#         # Permute to [channels, num_pieces_side, piece_height, num_pieces_side, piece_width]\n",
    "#         pieces = pieces.permute(2, 0, 3, 1, 4)\n",
    "# \n",
    "#         # Reshape to [channels, height, width]\n",
    "#         image = pieces.contiguous().view(channels, num_pieces_side * piece_height, num_pieces_side * piece_width)\n",
    "# \n",
    "#         return image\n",
    "# \n",
    "#     def log_images(self, trainer, pl_module, loader, prefix):\n",
    "#         if (trainer.current_epoch % self.plot_every_n_epoch == 0) or (trainer.current_epoch == h['epochs'] - 1):\n",
    "#             pl_module.eval()\n",
    "#             image_batch, label_batch = next(iter(loader))\n",
    "#             pieces, random_pieces, _ = batch_chunk_image(image_batch, self.num_pieces)\n",
    "#             pieces, random_pieces = pieces.to(pl_module.device), random_pieces.to(pl_module.device)\n",
    "# \n",
    "#             ordered_pieces, permutation_matrices = pl_module(random_pieces)\n",
    "#             # Assemble the pieces into a single image before logging\n",
    "#             nb_ims = min(ordered_pieces.shape[0], 10)\n",
    "#             for i in range(nb_ims):\n",
    "#                 initial_image = self.assemble_image(random_pieces[i])\n",
    "#                 ordered_image = self.assemble_image(ordered_pieces[i])\n",
    "#                 ground_truth_image = self.assemble_image(pieces[i])\n",
    "# \n",
    "#                 # log to wandb\n",
    "#                 self.wandb_logger.experiment.log(\n",
    "#                     {f\"{prefix}_predicted_image/img_{i}\": wandb.Image(ordered_image.cpu().squeeze(),\n",
    "#                                                                       caption=f\"Label {label_batch[i]}\"),\n",
    "#                      f\"{prefix}_ground_truth/img_{i}\": wandb.Image(ground_truth_image.cpu().squeeze(),\n",
    "#                                                                    caption=f\"Label {label_batch[i]}\"),\n",
    "#                      f\"{prefix}_input/img_{i}\": wandb.Image(initial_image.cpu().squeeze(),\n",
    "#                                                             caption=f\"Label {label_batch[i]}\")},\n",
    "#                     step=trainer.global_step)\n",
    "# \n",
    "#             pl_module.train()\n",
    "# \n",
    "#     def on_train_epoch_end(self, trainer: pl.Trainer, pl_module: SinkhornConvNet):\n",
    "#         self.log_images(trainer, pl_module, train_loader, \"TRAIN\")\n",
    "# \n",
    "#     def on_validation_epoch_end(self, trainer: pl.Trainer, pl_module: SinkhornConvNet):\n",
    "#         pass\n",
    "# \n",
    "#     def on_train_end(self, trainer, pl_module):\n",
    "#         self.log_images(trainer, pl_module, test_loader, \"TEST_SET_train_end\")\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "9614d75c960f9ff8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T13:35:29.385080Z",
     "start_time": "2024-07-30T13:35:28.946532Z"
    }
   },
   "source": [
    "# Initialize the model\n",
    "model = EnsembleNet(num_models=h['ensemble_size'])\n",
    "if h['train']:\n",
    "    if h['use_wandb']:\n",
    "        date_identifier = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        wandb_logger = WandbLogger()\n",
    "        wandb.init(project=h['wandb_project'],\n",
    "                   config=h,\n",
    "                   entity=h['wandb_entity'],\n",
    "                   name=h['wandb_name'])\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=h['epochs'],\n",
    "        # callbacks=[CustomCallbacks(plot_every_n_epoch=1, num_pieces=h['num_pieces'],\n",
    "        #                            wandb_logger=wandb_logger)] if h['use_wandb'] else None,\n",
    "        # logger=wandb_logger if h['use_wandb'] else None,\n",
    "        limit_train_batches=h['limit_train_batches'],\n",
    "        limit_val_batches=h['limit_val_batches'],\n",
    "        limit_test_batches=h['limit_test_batches'],\n",
    "        fast_dev_run=h['fast_dev_run'],\n",
    "        overfit_batches=h['overfit_batches'])\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, datamodule)\n",
    "    model.save()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model = model.load()\n",
    "    trainer.test(model, datamodule)\n",
    "\n",
    "    # Finish the run if  it was running\n",
    "    if wandb.run is not None:\n",
    "        wandb.finish()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Training with multiple optimizers is only supported with manual optimization. Set `self.automatic_optimization = False`, then access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 24\u001B[0m\n\u001B[0;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m L\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[0;32m     13\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39mh[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# callbacks=[CustomCallbacks(plot_every_n_epoch=1, num_pieces=h['num_pieces'],\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     fast_dev_run\u001B[38;5;241m=\u001B[39mh[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfast_dev_run\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     21\u001B[0m     overfit_batches\u001B[38;5;241m=\u001B[39mh[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moverfit_batches\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m model\u001B[38;5;241m.\u001B[39msave()\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:543\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 543\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[0;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:579\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    573\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    574\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    575\u001B[0m     ckpt_path,\n\u001B[0;32m    576\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    577\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    578\u001B[0m )\n\u001B[1;32m--> 579\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:962\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    959\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logger_connector\u001B[38;5;241m.\u001B[39mreset_metrics()\n\u001B[0;32m    961\u001B[0m \u001B[38;5;66;03m# strategy will configure model and move it to the device\u001B[39;00m\n\u001B[1;32m--> 962\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;66;03m# hook\u001B[39;00m\n\u001B[0;32m    965\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;241m==\u001B[39m TrainerFn\u001B[38;5;241m.\u001B[39mFITTING:\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:159\u001B[0m, in \u001B[0;36mStrategy.setup\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_model(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;241m==\u001B[39m TrainerFn\u001B[38;5;241m.\u001B[39mFITTING:\n\u001B[1;32m--> 159\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_optimizers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msetup_precision_plugin()\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;241m==\u001B[39m TrainerFn\u001B[38;5;241m.\u001B[39mFITTING:\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:139\u001B[0m, in \u001B[0;36mStrategy.setup_optimizers\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Creates optimizers and schedulers.\u001B[39;00m\n\u001B[0;32m    133\u001B[0m \n\u001B[0;32m    134\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m    trainer: the Trainer, these optimizers should be connected to\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \n\u001B[0;32m    137\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_scheduler_configs \u001B[38;5;241m=\u001B[39m \u001B[43m_init_optimizers_and_lr_schedulers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:192\u001B[0m, in \u001B[0;36m_init_optimizers_and_lr_schedulers\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m    186\u001B[0m optimizers, lr_schedulers, monitor \u001B[38;5;241m=\u001B[39m _configure_optimizers(optim_conf)\n\u001B[0;32m    187\u001B[0m lr_scheduler_configs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    188\u001B[0m     _configure_schedulers_automatic_opt(lr_schedulers, monitor)\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mautomatic_optimization\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m _configure_schedulers_manual_opt(lr_schedulers)\n\u001B[0;32m    191\u001B[0m )\n\u001B[1;32m--> 192\u001B[0m \u001B[43m_validate_multiple_optimizers_support\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    193\u001B[0m _validate_optimizers_attached(optimizers, lr_scheduler_configs)\n\u001B[0;32m    194\u001B[0m _validate_scheduler_api(lr_scheduler_configs, model)\n",
      "File \u001B[1;32mC:\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:357\u001B[0m, in \u001B[0;36m_validate_multiple_optimizers_support\u001B[1;34m(optimizers, model)\u001B[0m\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    352\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining with multiple optimizers is only supported with manual optimization. Remove the `optimizer_idx`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    353\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m argument from `training_step`, set `self.automatic_optimization = False` and access your optimizers\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    354\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m in `training_step` with `opt1, opt2, ... = self.optimizers()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    355\u001B[0m     )\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mautomatic_optimization \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(optimizers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 357\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    358\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining with multiple optimizers is only supported with manual optimization. Set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    359\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `self.automatic_optimization = False`, then access your optimizers in `training_step` with\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    360\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `opt1, opt2, ... = self.optimizers()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    361\u001B[0m     )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Training with multiple optimizers is only supported with manual optimization. Set `self.automatic_optimization = False`, then access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`."
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d8f7efe0350ece01",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
